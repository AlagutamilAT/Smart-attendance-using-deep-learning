import numpy as np
import librosa
import pyaudio
import wave
from scipy.spatial.distance import euclidean
from datetime import datetime
import os
import json

# Parameters
SAMPLE_RATE = 22050
DURATION = 2  # Duration of audio clip in seconds
CHUNK = 1024  # Audio chunk size
RECORD_SECONDS = 2
WAVE_OUTPUT_FILENAME = "voice.wav"
ATTENDANCE_FILE = 'attendance.csv'
FEATURES_FILE = 'known_features.json'

# Function to record audio
def save_voice_sample(filename):
    audio = pyaudio.PyAudio()
    stream = audio.open(format=pyaudio.paInt16, channels=1, rate=SAMPLE_RATE, input=True, frames_per_buffer=CHUNK)
    
    print("Recording...")
    frames = []
    for _ in range(0, int(SAMPLE_RATE / CHUNK * RECORD_SECONDS)):
        data = stream.read(CHUNK)
        frames.append(data)
    
    print("Finished recording.")
    stream.stop_stream()
    stream.close()
    audio.terminate()

    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))
        wf.setframerate(SAMPLE_RATE)
        wf.writeframes(b''.join(frames))

# Function to extract features from audio
def extract_features(file_name):
    audio, _ = librosa.load(file_name, sr=SAMPLE_RATE, duration=DURATION)
    mfccs = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=13)
    return np.mean(mfccs.T, axis=0)

# Function to recognize voice by comparing features
def recognize_voice(features, known_features):
    distances = {name: euclidean(features, np.array(known_feature)) for name, known_feature in known_features.items()}
    closest_match = min(distances, key=distances.get, default=None)
    return closest_match

# Function to mark attendance
def mark_attendance(name):
    with open(ATTENDANCE_FILE, 'a') as f:
        now = datetime.now()
        date_time = now.strftime("%Y-%m-%d %H:%M:%S")
        f.write(f"{name},{date_time}\n")

# Load known features from file
def load_known_features():
    if os.path.exists(FEATURES_FILE):
        with open(FEATURES_FILE, 'r') as f:
            return json.load(f)
    return {}

# Save known features to file
def save_known_features(features):
    with open(FEATURES_FILE, 'w') as f:
        json.dump(features, f)

def main():
    known_features = load_known_features()
    
    while True:
        print("Please say your name...")
        save_voice_sample(WAVE_OUTPUT_FILENAME)
        features = extract_features(WAVE_OUTPUT_FILENAME)

        recognized_name = recognize_voice(features, known_features)

        if recognized_name:
            mark_attendance(recognized_name)
            print(f"{recognized_name} marked as present.")
        else:
            print("Voice not recognized. Please provide a name for this voice.")
            name = input("Enter name for new voice: ").strip()
            known_features[name] = features.tolist()
            save_known_features(known_features)
            mark_attendance(name)
            print(f"{name} has been registered and marked as present.")

        # Ask if the user wants to continue or exit
        continue_choice = input("Do you want to record another voice? (yes/no): ").strip().lower()
        if continue_choice != 'yes':
            break

    print("Process completed. Exiting the program.")

if __name__ == "__main__":
    main()
